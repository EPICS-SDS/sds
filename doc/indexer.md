# Storage and Indexer service
The data will be stored in files and indexed by a database to allow for complex searches based on triggering event, time, or PVs.

## Storage
Data is stored in HDF5 files following the NeXus convention. Each file corresponds to a set of PVs from the configuration file and it can contain one or more events. The file structure is as follows:

    file
    - entry (NXEntry). Attributes: SDS collector version, dataset name,  event name, event type (#)
      - data
        - event_pulseID_0 (NXData). Attributes: timestamp, pulse ID
          - PV_0:
            - pulse_ID_-K: pre-buffer value(s)
            - ...
            - pulse_ID_0: 
            - ...
            - pulse_ID_L: post-buffer value(s)
          - ...
          - PV_N
        - event_pulseID_1 (NXData). Attributes: timestamp, pulse ID
          - PV_0
          - ...
          - PV_N
        - ...

The NeXus files are saved in a distributed network storage.

The filename is generated using the set name defined in the configuration file, followed by a timestamp with the format:
`dataset_name_YYYYmmdd_HHMMSS.h5`
The timestamp should be the time when the file was created.

### Directory tree structure
The data will be organized according to the following directory structure:
- year (YYYY)
  - day (YYYY-mm-dd)
    - files

## Indexer service
Part of the files metadata is also stored in a database for faster searches, based on elasticsearch.
Elasticsearch will keep 3 indexes, one for the dataset structure that will be repeated over many events, another index for the events, and the third one is to keep track of short term data storage.

The dataset index will contain the following information:
- unique ID (auto-generated by ES)
- dataset name
- event name
- event type
- list of PVs

The unique ID is required since the configuration can be updated to add or remove PVs from a dataset.

The second index will store:
- unique ID (auto-generated by ES)
- timestamp (UNIX timestamp in UTC)
- trigger pulse_ID
- dataset unique ID
- file path

Finally the third index will contain the following information:
- dataset unique ID
- expire by (UNIX timestamp in UTC)

## API
The API of the indexer service will have one entrypoint for adding a new dataset definition and one to add data:

- `/get_ds` POST operation that returns the ID of the dataset that matches the parameters. If the dataset does not exist, it creates it. Parameters:
  - `ds_name` (required): a string with the name given to the dataset. It should be the one defined in the collector configuration file as `name`. It does not need to be unique.
  - `ev_name` (required): a string with the event name as defined in the timing system.
  - `ev_type` (required): an integer with the event type as defined in the timing system.
  - `pv_list` (required): list of PVs that belong to this dataset. It can be given as a comma-separated list of PVs, or by giving the pv_list parameter multiple times.
- `/add_event` POST operation that adds an event to the events index and returns the unique ID of the event. Parameters:
  - `ds_id` (required): the string returned by the `/get_ds` operation.
  - `ev_timestamp` (required): an integer with the event timestamp in nanoseconds.
  - `tg_pulse_id` (required): an integer with the pulse ID corresponding to the triggering event.
  - `path` (required): a string with the path to the NeXus file with the data, stored in a shared NFS system.
  - `expire_in` (optional): an integer that determines if the event should be removed from the storage after some time. By default events are stored forever. It is up to the collector service to define this time for each event to fulfill the data reduction policy.

NOTE: This API is to be used only by the collector services.